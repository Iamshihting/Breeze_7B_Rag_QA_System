{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=PyPDFLoader('Neoway.pdf')\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=470,chunk_overlap=260)\n",
    "documents=loader.load()\n",
    "documents_texts = \"\"\n",
    "documents_texts = '\\n'.join([doc.page_content[2:] for doc in documents])\n",
    "documents_texts = re.sub(r'(第[一二三四五六七八九十]+章.*?)(?=\\n)', '', documents_texts)\n",
    "documents_texts = re.sub(r'\\n ?(第.{1,5}條(?:之.)*)', r'@\\1', documents_texts)\n",
    "documents_texts = documents_texts.replace('\\n', '').replace(' ','').replace('@', ' ')\n",
    "texts=text_splitter.split_text(documents_texts)\n",
    "print(documents_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=HuggingFaceEmbeddings(model_name=\"paraphrase-multilingual-MiniLM-L12-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'db' in locals(): db.delete_collection()\n",
    "db=Chroma.from_texts(texts,embeddings,persist_directory=\"db\", collection_metadata={\"hnsw:space\": \"cosine\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"MediaTek-Research/Breeze-7B-Instruct-v0_1\",\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    attn_implementation=\"flash_attention_2\" # optional\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"MediaTek-Research/Breeze-7B-Instruct-v0_1\")\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=500)\n",
    "llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever( search_kwargs={'k': 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = retriever.invoke(\"員工申訴處理制度是什麼？\")\n",
    "for i in a:\n",
    "  print(re.findall(r'第.{1,5}條(?:之.)*', i.page_content))\n",
    "  print(i.page_content)\n",
    "  print('='*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "template = \"\"\"你是問答任務的助手。注意:請根據以下文章來回答問題。注意:如果你在文章中找不到答案，請回答\"沒有提及\"。答案只能從文章內尋找，請勿根據其他資訊來回答。\n",
    "\n",
    "文章:{context}\n",
    "\n",
    "問題:{question}\n",
    "\n",
    "請詳細回答並說明。\n",
    "\n",
    "回答:\"\"\"\n",
    "custom_rag_prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | custom_rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "df = pd.read_excel(\"Questions_Answers.xlsx\")\n",
    "question = df['Query']\n",
    "answer = df['標準答案_新向系統']\n",
    "for (ques,ans) in zip(question,answer):\n",
    "  print(ques)\n",
    "  if ques == None:\n",
    "    break\n",
    "  print(\"模型答案:\",rag_chain.invoke(ques))\n",
    "  print(\"標準答案:\",ans)\n",
    "  print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "breeze2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
